{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "# Bonus Lecture 6.3 - Google's PageRank Algorithm\n",
    "\n",
    "## For enthusiasts\n",
    "\n",
    "The material below is entirely optional $-$ it is not core material for the course and you do not need to study it.  \n",
    "\n",
    "\n",
    "(But you might find it useful in any future re-reading of the course.)\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "### Programming\n",
    "\n",
    "- Generating matrices for the PageRank Algorithm\n",
    "- Implementation of the PageRank Algorithm\n",
    "\n",
    "\n",
    "### Mathematics \n",
    "- Derivation of the Page Rank Algorithm\n",
    "- Working with Sink pages \n",
    "- Working with a disconnected web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google's PageRank Algorithm ##\n",
    "\n",
    "Search engines rank the importance of web pages as a means of finding the most relevant web pages to a search request.   The early search engines used a *text based ranking system* in which pages would be ranked, for example, by the number of instances of a search keyword in the page. These engines were notoriously inefficient and prone to unwanted manipulation. For example, dodgy websites were able to obtain high rankings, and so be prioritised by web searches simply by containing many copies of common keywords. This all changed when Larry Page and Sergey Brin invented the *PageRank* algorithm while they were graduate students at Standford. The idea that Brin and Page had was that the importance of a web page is determined by the links that are made to the page. More precisely, each link conveys an importance *weighting* to the webpage to which it points. The rank/importance of a webpage is then simply the sum of all the weightings of the links pointing to it. To see how this work lets start with a simple web consisting of five pages. Note that we view this as a directed graph where the arrows denote links from one page to another. \n",
    "\n",
    "<img src=\"webOne.jpg\" alt=\"webOne\" style=\"width: 400px\">\n",
    "\n",
    "As you can see we  know nothing about the ranking of these pages in advance. We assume at the start of our algorithm that each page has the same rank. Thus, letting $\\mathbf{p}^{(0)} = (p^{(0)}_1,p^{(0)}_2,p^{(0)}_3,p^{(0)}_4,p^{(0)}_5)^T$ denote the vector of page ranks we have (at step zero) $p^{(0)}_i = \\frac{1}{5}$ for $i = 1,\\dots,5$.  This means that the cumulative page rank is given by \n",
    "$$\n",
    "\\|\\mathbf{p}^{(0)}\\|_1 = \\sum^{5}_{i = 1} p^{(0)}_i = 1 \\,. \n",
    "$$ \n",
    "The idea is that each  page will distribute among the pages that it links to (i.e. at  the end of the arrows emanating from it) an equal  proportion of its present rank/importance. For example page 1 has (out) links to pages 2, 4 and 5 and so distributes one third of its present rank to each of these.\n",
    "\n",
    "<img src=\"webTwo.jpg\" alt=\"webTwo\" style=\"width: 550px\">\n",
    "\n",
    "Each page rank is now updated to the total rank weighting that it receives from its incoming links and this gives us our new page rank vector $\\mathbf{p}^{(1)}$ at the end of step 1. For example \n",
    "$p^{(1)}_2 = \\frac{1}{3} \\cdot p^{(0)}_1  + 1 \\cdot p^{(0)}_4$ because page 2 is pointed to by one of the three links on page 1 and  by the unique link on page 4. Accordingly we have \n",
    "\\begin{align*}                                                                                                    \n",
    "  p^{(1)}_1 \\;&=\\; \\frac{1}{2} \\cdot p^{(0)}_2 \\,, \\\\                                                             \n",
    "  p^{(1)}_2 \\;&=\\; \\frac{1}{3} \\cdot p^{(0)}_1  + 1 \\cdot p^{(0)}_4 \\,, \\\\                                        \n",
    "  p^{(1)}_3 \\;&=\\; \\frac{1}{2} \\cdot p^{(0)}_2  + \\frac{1}{2} \\cdot p^{(0)}_5 \\,, \\\\                              \n",
    "  p^{(1)}_4 \\;&=\\; \\frac{1}{3} \\cdot p^{(0)}_1  + 1 \\cdot p^{(0)}_3 + \\frac{1}{2} \\cdot p^{(0)}_5 \\,, \\\\          \n",
    "  p^{(1)}_5 \\;&=\\; \\frac{1}{3} \\cdot p^{(0)}_1   \\,,                                                              \n",
    "\\end{align*} \n",
    "which can be written \n",
    "$$                                                                                                                \n",
    "\\mathbf{p}^{(1)} \\,=\\, A \\mathbf{p}^{(0)} \\,,                                                                     \n",
    "\\qquad                                                                                                            \n",
    "\\text{ where }                                                                                                    \n",
    "A \\,=\\,                                                                                                           \n",
    "\\begin{pmatrix}                                                                                                   \n",
    "0 & \\frac{1}{2} & 0 & 0 & 0 \\\\                                                                                    \n",
    "\\frac{1}{3} & 0 & 0 & 1 & 0 \\\\                                                                                    \n",
    "0 &  \\frac{1}{2} & 0  & 0 & \\frac{1}{2} \\\\                                                                        \n",
    "\\frac{1}{3} & 0 & 1 & 0 & \\frac{1}{2} \\\\                                                                          \n",
    "\\frac{1}{3} & 0 & 0 & 0 & 0                                                                                       \n",
    "\\end{pmatrix}  \\, .                                                                                                   \n",
    "$$      \n",
    "\n",
    "**Note.** As a general rule $a_{ij}$ - the entry in the $i$th row and $j$th column of $A$ - is $0$ if there are no links from page $j$ to page $i$ and $1/n_j$ if there is a link from page $j$ to page $i$ where $n_j$ is the total number of (out) links on page $j$.   \n",
    "\n",
    "Our algorithm now iterates this process to get $\\mathbf{p}^{(2)} = A\\mathbf{p}^{(1)} = A^2 \\mathbf{p}^{(0)}$ and in general, for $k > 0$, \n",
    "\n",
    "$$                                                                                                                \n",
    "\\mathbf{p}^{(k)} = A\\mathbf{p}^{(k-1)} = A^k \\mathbf{p}^{(0)} \\,.                                                 \n",
    "$$                                                                                                                \n",
    "                                                                                                                  \n",
    "In fact we find that there is a page rank vector $\\mathbf{p}$ such that $\\mathbf{p}^{(k)} \\rightarrow \\mathbf{p}$ \n",
    "as $k \\rightarrow \\infty$, so that $\\mathbf{p}$ satisfies    \n",
    "\n",
    "$$                                                                                                                \n",
    "\\mathbf{p} \\,=\\, A \\mathbf{p} \\,.                                                                                 \n",
    "$$      \n",
    "\n",
    "In other words $\\mathbf{p}$ is an eigenvector of $A$ with associated eigenvalue $\\lambda = 1$.                    \n",
    "                                                                                                                  \n",
    "**Remark 1.** It can be proved  that $\\lambda = 1$ is the (strictly) largest eigenvalue of $A$ as it is *column stochastic*, i.e. the entries in each column add up to one. Note however that we cannot be sure that there is only one \n",
    "eigenvector of the same type as $\\mathbf{p}$ (in the sense that its entries add to $1$) with eigenvalue $1$ as you will see in our example of a disconnected web below. In fact the transition matrix that we will use - the matrix $M$ - below will be both *column stochastic* and *positive* meaning that all its entries are positive. The *Perron-Frobenius Theorem* now tells us that, for such a matrix, there is a unique eigenvector whose entries add to $1$ (as is the case for $\\mathbf{p}$) associated with the eigenvalue $1$.    \n",
    "\n",
    "**Remark 2.** We also have that $\\|\\mathbf{p}^{(k)}\\|_1 = 1$ for all $k \\ge 1$ given that  $\\|\\mathbf{p}^{(0)}\\|_1 = 1$. Indeed, as  $A$ is column stochastic, multiplication  of   $\\mathbf{p}^{(k-1)}$ by $A$\n",
    "redistributes the entries of $\\mathbf{p}^{(k-1)}$ in such a way that their sum is preserved in the resulting vector $\\mathbf{p}^{(k)}$.\n",
    "\n",
    "You may now have spotted that the iterative process $\\mathbf{p}^{(k)} = A\\mathbf{p}^{(k-1)}$ at the heart of our algorithm is nothing more than the *power method* in which the iterates converge to eigenvector $\\mathbf{p}$\n",
    "associated with the largest eigenvalue $\\lambda = 1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank and  Sink Pages ###\n",
    "\n",
    "In the example above all the pages had at least one link pointing to another page. But what happens if there is a page with no outgoing links. This is the case for page 2 in the three page web below. We call page 2 a *sink* (or *dangling*) page in this case. \n",
    "\n",
    "<img src=\"webThree.jpg\" alt=\"webThree\" style=\"width: 400px\">\n",
    "\n",
    "Note that here we have transition matrix \n",
    "$$\n",
    "A \\,=\\,                                                                                                           \n",
    "\\begin{pmatrix}                                                                                                   \n",
    "0 &  0 & 0 \\\\                                                                                    \n",
    "1 & 0  & 1 \\\\ \n",
    "0 &  0 & 0 \n",
    "\\end{pmatrix}  \n",
    "$$\n",
    "\n",
    "and initial page rank vector $\\mathbf{p}^{(0)} = (\\frac{1}{3},\\frac{1}{3},\\frac{1}{3})$. And our algorithm goes horribly wrong. Indeed, as we see in the cell below, $\\mathbf{p}^{(2)} = A \\mathbf{p}^{(1)} = (0,0,0)^T$, so that \n",
    "all our pages end up with rank 0. This is not what we want. Note that in this example the matrix is not column stochastic as the second column has sum 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to see the first 3 iterates of the page rank vector above\n",
    "import numpy as np \n",
    "import numpy.linalg as lag\n",
    "\n",
    "A = np.array([[0., 0., 0.], [1, 0 , 1], [0, 0, 0]]) # Our transition matrix\n",
    "p = np.array([1,1,1])                               # The original page rank per page is 1/3 \n",
    "p = p / lag.norm(p,1)                               # p = (1/3,1/3,1/3) now. \n",
    "\n",
    "np.set_printoptions(precision=3)                    # Print out to only 3 decimal places \n",
    "print(\"p^(0) = \" + str(p) + \"^T\")                   # Print the initial value of p\n",
    "\n",
    "for i in range(2):                                  # Compute and print further iterates of p.\n",
    "    p = np.dot(A,p)\n",
    "    print(\"p^(\" + str(i+1) + \") = \" + str(p) + \"^T\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with a sink page we will use the simple strategy of distributing the page's present rank evenly to every page of the web. Thus in our example we obtain \n",
    "\n",
    "$$\n",
    "A \\,=\\,                                                                                                           \n",
    "\\begin{pmatrix}                                                                                                   \n",
    "0 &  \\frac{1}{3} & 0 \\\\                                                                                    \n",
    "1 & \\frac{1}{3}  & 1 \\\\ \n",
    "0 &  \\frac{1}{3} & 0 \n",
    "\\end{pmatrix}\\,.  \n",
    "$$ \n",
    "\n",
    "Of course here this strategy clearly radically changes our underlying model. However for a web with a large number of pages this makes sense since any non sink page only has links to a relatively small number of pages. Thus the rank weight that a sink page distributes to any given page is very small compared with the rank weight distribution performed by an actual link.)     \n",
    "\n",
    "**Note.** The matrix $A$ is now column stochastic. \n",
    "\n",
    "**Remark 3.** An isolated page is a sink by  definition as it has no outgoing links (as well as no incoming links). It is also a special case of the type of  disconnected components that we now consider. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank and a Disconnected Web ###\n",
    "\n",
    "Another problem that the PageRank algorithm has to deal with is the fact that the world wide web has disconnected components, i.e.  sets of pages with no links between the different sets. The example below shows a disconnected web with two disconnected components of size 2 and 3 (pages) each. \n",
    "\n",
    "<img src=\"webFour.jpg\" alt=\"webFour\" style=\"width: 400px\">\n",
    "\n",
    "Now, we can think of the PageRank algorithm as modelling a random surfer (where each link weighting represents the probability of the surfer clicking on/following that link). According to this model sink pages are where the random surfer gets stuck. In this case (see above) we allowed the surfer  to be teleported to any page on the web with equal probability. Here we have a similar problem in which the random surfer is trapped inside a single component (instead of at a single page). Here the transition matrix for the example is\n",
    "\n",
    "$$                                                                                                                     \n",
    "A \\,=\\,                                                                                                           \n",
    "\\begin{pmatrix}                                                                                                   \n",
    "0 & 1 & 0 & 0 & 0 \\\\                                                                                    \n",
    "1 & 0 & 0 & 0 & 0 \\\\                                                                                    \n",
    "0 &  0 & 0  & \\frac{1}{2} & \\frac{1}{2} \\\\                                                                        \n",
    "0 & 0 & \\frac{1}{2} & 0 & \\frac{1}{2}\\\\                                                                          \n",
    "0 & 0 & \\frac{1}{2} & \\frac{1}{2} & 0                                                                                 \n",
    "\\end{pmatrix}  \\, .                                                                                                   \n",
    "$$      \n",
    "\n",
    "By inspection we can see that both $\\mathbf{p} = (1/2,1/2,0,0,0)^T$ and $\\mathbf{q} = (0,0,1/3,1/3,1/3)^T$ are eigenvectors of $A$ associated with eigenvalue $1$ (and each with entries summing to $1$). So our \n",
    "algorithm is not well defined in this case. What Brin and Page proposed was for the random surfer, with probability\n",
    "$1-d \\approx 0.15$ (so $d \\approx 0.85$ - Brin and Page called this the *damping parameter*), to jump/teleport from the present page to any  page on the web instead of clicking on/following a link. Note that this corresponds to the page distributing $1-d$ times its present rank evenly between every page of the web. \n",
    "\n",
    "### Full version of the PageRank algorithm ###\n",
    "\n",
    "Now, given a web with $n$ pages, we define $A$ to be the $n \\times n$ transition matrix and we define $B$ to be the $n \\times n$ matrix in which every column corresponding to a sink contains $1/n$ in each entry and in which every other column is all zero. (Note that this means that $A + B$ is simply the modification of $A$ where every zero column has been replaced by a column containing $1/n$ in each entry.)   We then define the $n \\times n$ matrix\n",
    "\n",
    "$$                                                                                                             \n",
    "M \\,=\\, d(A + B) + (1-d)C, \\quad \\text{where }                                                                       \n",
    "C \\,=\\,                                                                                                        \n",
    "\\frac{1}{n}                                                                                                    \n",
    "\\begin{pmatrix}                                                                                                \n",
    "  1 & 1 & \\cdots & 1 \\\\                                                                                        \n",
    "  1 & \\ddots & & \\vdots \\\\                                                                                     \n",
    "  \\vdots & &  &  \\\\                                                                                            \n",
    "  1 & \\cdots & & 1                                                                                             \n",
    "\\end{pmatrix} \\,.                                                                                                    \n",
    "$$             \n",
    "\n",
    "Our algorithm now proceeds via the iteration \n",
    "$$                                                                                                             \n",
    "\\mathbf{p}^{(k)} = M \\mathbf{p}^{(k-1)} = M^k \\mathbf{p}^{(0)}                                                 \n",
    "$$                                                                                                             \n",
    "for $k \\ge 1$, with $\\|\\mathbf{p}^{(0)}\\|_1 = 1$ as before. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note.** Our matrix $M$ is both both column stochastic and positive. Hence as mentioned in Remark 2, $1$ is the (striclty) greatest eigenvalue of $M$ and there is a unique eigenvector $\\mathbf{p}$ associated with this eigenvalue, whose entries sum to $1$. This means that $\\mathbf{p} = M \\mathbf{p}$ and that  $\\mathbf{p}$ is the vector that will be computed by the PageRank algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of the Algorithm ###\n",
    "\n",
    "We now implement  PageRank in python as a function that takes as input  a positive number `n`, a list `links` of pairs of numbers in the range `1` to `n` and a small floating point number `tol`. Here we mean that the input web has pages \n",
    "$1$ to $n$, and that each pair `(i,j)` in `links` corresponds to a link from page $j$ to page $i$. `tol` is the tolerance that defines how \"close together\" two iterates of the page rank vector `p_rank` computed by the algorithm have to be for it to terminate. Once this happens our function outputs the last computed iterate of `p_rank`.\n",
    "\n",
    "First we need the right libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from numpy import linalg as lag "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also modularise the overall task by first implementing the function `make_pagerank_matrices` which given inputs `n` and `links` as just described, outputs the transition matrix `A` and matrix `B` whose columns correspond to sinks. This function is then called by the `pagerank` function. \n",
    "\n",
    "Note that numpy arrays all start at index $0$. Thus a page $k$ in the range $1$ to $n$ corresponds to the $k-1$th row and the $k-1$th column of transition matrix $A$. A similar comment applies to the other matrices and arrays that we use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pagerank_matrices(n,links): \n",
    "    \"\"\" \n",
    "    Given input n representing n pages, a list of ordered pairs \"links\" representing\n",
    "    links between pages make_pagerank_matrices outputs a pair of matrices (A,B) where A is \n",
    "    the transition matrix of the associated web and B is the matrix whose columns correspond\n",
    "    to teleporting out of sink pages. \n",
    "    \"\"\"\n",
    "    A = np.zeros((n,n))\n",
    "    B = np.zeros((n,n))\n",
    "    is_sink_page = np.full((n,), True)  # is_sink_page = [True,...,True] is our first guess \n",
    "                                        # that every column is a sink, \n",
    "    for (i,j) in links: \n",
    "        A[i-1,j-1] = 1                  # Update the transition matrix A \n",
    "        is_sink_page[j-1] = False       # The existence of a link (j,i) means that page j \n",
    "                                        # is not a sink. Setting the j-1'th component of \n",
    "                                        # the array is_sink_page registers this fact. \n",
    "                \n",
    "    for col in range(n):                # is_sink_page[col] is now True iff page col+1 is a sink \n",
    "        if is_sink_page[col]:           # so we fill the colun col of B with 1's \n",
    "            B[:,col] = np.ones(n) \n",
    "    \n",
    "    for M in (A,B):                     # Both matrices A and B contain numbers 0 and 1\n",
    "        for j in range(n):              # In both cases we can obtain the appropriate matrix\n",
    "            column = M[:,j]             # by summing the number of ones in each nonzero column and\n",
    "            column_sum = column.sum()   # dividing through each entry in the column by this sum \n",
    "            if column_sum > 0: \n",
    "                M[:,j] = column / column_sum \n",
    "    \n",
    "            \n",
    "    return (A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for `pagerank` itself. Note that instead of choosing the original value of the page rank vector `p_rank` to have all entries set to $1/n$ we define `p_rank` to be a normalised positive random vector - i.e. containing random positive entries that add to one - so conforming with the power method approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(n,links,tol): \n",
    "    \"\"\"\n",
    "    Given input n representing n pages, a list of ordered pairs \"links\" representing\n",
    "    links between pages, and a tolerance tol used to terminate the computation, \n",
    "    pagerank computes the n component vector of relative rank/importance of each page. \n",
    "    \"\"\"\n",
    "    d = 0.85                                    # d is the damping factor\n",
    "    \n",
    "    (A, B) = make_pagerank_matrices(n,links)    # A is the transtion matrix, B the \"sink\" matrix\n",
    "    C = np.ones((n,n)) / n                      # C is the general teleporting matrix to deal with  \n",
    "                                                # disconnected components \n",
    "    M = d * (A + B) + (1 - d) * C               # M is the n x n matrix used for updating the page rank vector. \n",
    "        \n",
    "    p_rank = np.random.random((n,))             # Our original guess at the page rank is an n component \n",
    "    p_rank = p_rank / lag.norm(p_rank,1)        # vector with random positive entries. Normalised on this line\n",
    "                                                # so that the entries add to 1.\n",
    "        \n",
    "    p_old = np.zeros((n,))                      # We also need a vector that stores that last iterate of p_rank\n",
    "                                                # We set it to zero so that ||p_rank - p_old|| > tol to force the \n",
    "                                                # loop below to continue past the first step. \n",
    "            \n",
    "    while (lag.norm(p_rank - p_old) > tol):     # Loop contines until the distance between two consecutive \n",
    "                                                # iterates is at most tol\n",
    "        p_old = p_rank                          # p_old is updated to the previous value of p_rank\n",
    "        p_rank = np.dot(M,p_old)                # p_rank is updated by multiplying its previous value by matrix M\n",
    "        \n",
    "    return p_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test our algorithm on the 5 page web described in Figure 1. First we need a list of the links. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [(2,1),(4,1),(5,1),(1,2),(3,2),(4,3),(2,4),(3,5),(4,5)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we start by checking that `make_pagerank_matrices` works properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(A,B) = make_pagerank_matrices(5,links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "print(\"A = \\n\" + str(A) + \"\\n\")\n",
    "print(\"B = \\n\" + str(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. $A$ is indeed the transition matrix and $B$ is the zero matrix as there are no sinks. Now we apply `pagerank` itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rank = pagerank(5,links,1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's print out our results nicely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(p_rank)): \n",
    "    #print(\"Page \" + str(i+1) + \"has importance \" + str(p_rank[i]))\n",
    "    print(\"Page {} has importance {:.2f}\".format(i+1,p_rank[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the pages ranked in terms of importance are  \n",
    "\n",
    "1. Page 2,\n",
    "2. Page 4, \n",
    "3. Page 3,\n",
    "4. Page 1, \n",
    "5. Page 5.\n",
    "\n",
    "This might surprise you, in that page 2 is ranked above page 4. However this does make sense when we  note that page 4 distributes all of its importance/rank to page 2 via a unique link.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
